#!/usr/bin/env bash
set -euo pipefail
IFS=$'\n\t'

# ----------------------
# Configuration - EDIT
# ----------------------
REGION="us-east-1"                        # N. Virginia
AWS_PROFILE=""                            # optional: set to profile name or leave empty
BUCKET_NAME="ec2-backups-$(date +%s)"     # must be globally unique
KEY_NAME="ec2-backup-key-$(date +%s)"     # SSH keypair name
INSTANCE_TYPE="t3.micro"
INSTANCE_NAME="ec2-backup-instance"
IAM_ROLE_NAME="EC2_S3_Backup_Role_$(date +%s)"
INSTANCE_PROFILE_NAME="${IAM_ROLE_NAME}-profile"
SEC_GROUP_NAME="ec2-backup-sg-$(date +%s)"
BACKUP_DIR="/backup"
CREATE_SNAPSHOTS="yes"                    # yes/no
SNAPSHOT_TAG="AutoBackup"
# The set of S3 subfolders to create & seed
S3_PREFIXES=("sales" "inventory" "workshop" "backup")
# ----------------------

# Convert CRLF to LF if script was edited on Windows (safe no-op if already LF)
if grep -q $'\r' "$0"; then
  echo "Converting CRLF -> LF in this script..."
  tmpf="$(mktemp)"
  tr -d '\r' < "$0" > "$tmpf"
  cat "$tmpf" > "$0"
  rm -f "$tmpf"
  echo "Converted script line endings. Re-run the script now."
  exit 0
fi

# Build AWS CLI base command as an array to avoid accidental single-string commands
AWS_CLI=(aws --region "${REGION}")
if [ -n "${AWS_PROFILE}" ]; then
  AWS_CLI+=(--profile "${AWS_PROFILE}")
fi

# helper to run aws commands
aws_run() {
  "${AWS_CLI[@]}" "$@"
}

# Requirements check
if ! command -v aws >/dev/null 2>&1; then
  echo "ERROR: aws CLI not found. Install & configure AWS CLI v2 and retry."
  exit 1
fi
if ! command -v jq >/dev/null 2>&1; then
  echo "ERROR: jq not found. Install jq and retry."
  exit 1
fi

echo "Using AWS region: ${REGION}"
echo "S3 bucket name: ${BUCKET_NAME}"
echo "IAM role name: ${IAM_ROLE_NAME}"
echo

# 0) Find latest Amazon Linux 2 AMI (owner 137112412989 is Amazon)
echo "0) Finding latest Amazon Linux 2 AMI in ${REGION}..."
AMI_ID=$(aws_run ec2 describe-images \
  --owners 137112412989 \
  --filters "Name=name,Values=amzn2-ami-hvm-*-x86_64-gp2" "Name=state,Values=available" \
  --query 'Images | sort_by(@, &CreationDate) | [-1].ImageId' \
  --output text)

if [ -z "${AMI_ID}" ] || [ "${AMI_ID}" = "None" ]; then
  echo "ERROR: Could not find Amazon Linux 2 AMI automatically. Please set AMI_ID manually."
  exit 1
fi
echo "Selected AMI: ${AMI_ID}"
echo

# 1) Create S3 bucket (special-case for us-east-1)
echo "1) Creating S3 bucket: ${BUCKET_NAME} ..."
if aws_run s3api head-bucket --bucket "${BUCKET_NAME}" 2>/dev/null; then
  echo "Bucket exists and accessible."
else
  if [ "${REGION}" = "us-east-1" ]; then
    aws_run s3api create-bucket --bucket "${BUCKET_NAME}"
  else
    aws_run s3api create-bucket --bucket "${BUCKET_NAME}" --create-bucket-configuration LocationConstraint="${REGION}"
  fi

  aws_run s3api put-bucket-versioning --bucket "${BUCKET_NAME}" --versioning-configuration Status=Enabled

  tmp_enc=$(mktemp)
  cat > "${tmp_enc}" <<'EJSON'
{"Rules":[{"ApplyServerSideEncryptionByDefault":{"SSEAlgorithm":"AES256"}}]}
EJSON
  aws_run s3api put-bucket-encryption --bucket "${BUCKET_NAME}" --server-side-encryption-configuration file://"${tmp_enc}"
  rm -f "${tmp_enc}"
  echo "Bucket created: versioning + default encryption enabled."

  # --- New: create S3 prefixes (folders) and seed them with a small README object ---
  echo "Seeding S3 prefixes: ${S3_PREFIXES[*]}"
  for prefix in "${S3_PREFIXES[@]}"; do
    # Create a small readme locally, upload as object to create the folder in S3
    tmp_readme="$(mktemp)"
    cat > "${tmp_readme}" <<EOF
This object seeds the '${prefix}/' prefix in bucket ${BUCKET_NAME}.
Created at $(date -u +"%Y-%m-%dT%H:%M:%SZ").
EOF
    aws_run s3api put-object --bucket "${BUCKET_NAME}" --key "${prefix}/README.txt" --body "${tmp_readme}" >/dev/null
    rm -f "${tmp_readme}"
    echo "Created s3://${BUCKET_NAME}/${prefix}/README.txt"
  done
  # --- end seeding ---
fi
echo

# 2) Create IAM role (EC2 assume-role) + inline policy
echo "2) Creating IAM role and inline policy..."
TRUST_FILE=$(mktemp)
cat > "${TRUST_FILE}" <<'JSON'
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect":"Allow",
      "Principal":{"Service":"ec2.amazonaws.com"},
      "Action":"sts:AssumeRole"
    }
  ]
}
JSON

set +e
ROLE_CREATE_OUT=$(aws_run iam create-role --role-name "${IAM_ROLE_NAME}" --assume-role-policy-document "file://${TRUST_FILE}" 2>/dev/null || true)
set -e

if [ -n "${ROLE_CREATE_OUT}" ]; then
  ROLE_ARN=$(echo "${ROLE_CREATE_OUT}" | jq -r '.Role.Arn')
else
  ROLE_ARN=$(aws_run iam get-role --role-name "${IAM_ROLE_NAME}" --query 'Role.Arn' --output text)
fi
rm -f "${TRUST_FILE}"
echo "Role ARN: ${ROLE_ARN}"

POLICY_FILE=$(mktemp)
cat > "${POLICY_FILE}" <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect":"Allow",
      "Action":[
        "s3:PutObject",
        "s3:GetObject",
        "s3:ListBucket",
        "s3:DeleteObject",
        "s3:PutObjectAcl"
      ],
      "Resource":[
        "arn:aws:s3:::${BUCKET_NAME}",
        "arn:aws:s3:::${BUCKET_NAME}/*"
      ]
    },
    {
      "Effect":"Allow",
      "Action":[
        "ec2:CreateSnapshot",
        "ec2:DescribeSnapshots",
        "ec2:DescribeVolumes",
        "ec2:CreateTags",
        "ec2:DescribeInstances"
      ],
      "Resource":"*"
    },
    {
      "Effect":"Allow",
      "Action":[
        "logs:CreateLogGroup",
        "logs:CreateLogStream",
        "logs:PutLogEvents"
      ],
      "Resource":"*"
    }
  ]
}
EOF

aws_run iam put-role-policy --role-name "${IAM_ROLE_NAME}" --policy-name "${IAM_ROLE_NAME}-policy" --policy-document file://"${POLICY_FILE}"
rm -f "${POLICY_FILE}"
echo "Inline policy attached."
echo

# 3) Create instance profile and attach role
echo "3) Creating instance profile and attaching role..."
set +e
aws_run iam create-instance-profile --instance-profile-name "${INSTANCE_PROFILE_NAME}" >/dev/null 2>&1 || true
aws_run iam add-role-to-instance-profile --instance-profile-name "${INSTANCE_PROFILE_NAME}" --role-name "${IAM_ROLE_NAME}" >/dev/null 2>&1 || true
set -e
echo "Instance profile ready: ${INSTANCE_PROFILE_NAME}"
echo

# Wait for IAM propagation
echo "Waiting 10 seconds for IAM propagation..."
sleep 10
echo

# 4) Create Security Group
echo "4) Creating security group: ${SEC_GROUP_NAME} ..."
VPC_ID=$(aws_run ec2 describe-vpcs --query 'Vpcs[0].VpcId' --output text)
if [ -z "${VPC_ID}" ] || [ "${VPC_ID}" = "None" ]; then
  echo "ERROR: Could not determine VPC ID in ${REGION}."
  exit 1
fi

SG_ID=$(aws_run ec2 create-security-group --group-name "${SEC_GROUP_NAME}" --description "SG for EC2 backup instance" --vpc-id "${VPC_ID}" --query 'GroupId' --output text)
# allow SSH (production: lock down CIDR)
aws_run ec2 authorize-security-group-ingress --group-id "${SG_ID}" --protocol tcp --port 22 --cidr 0.0.0.0/0 || true
echo "Security group created: ${SG_ID}"
echo

# 5) Create or import key pair
echo "5) Preparing key pair: ${KEY_NAME} ..."
if [ ! -f "${KEY_NAME}.pem" ]; then
  echo "Creating key pair in AWS and saving ${KEY_NAME}.pem locally..."
  aws_run ec2 create-key-pair --key-name "${KEY_NAME}" --query 'KeyMaterial' --output text > "${KEY_NAME}.pem"
  chmod 600 "${KEY_NAME}.pem"
  echo "Saved ${KEY_NAME}.pem"
else
  echo "Local ${KEY_NAME}.pem exists."
  if ! aws_run ec2 describe-key-pairs --key-names "${KEY_NAME}" >/dev/null 2>&1; then
    PUBKEY=$(ssh-keygen -y -f "${KEY_NAME}.pem")
    aws_run ec2 import-key-pair --key-name "${KEY_NAME}" --public-key-material "${PUBKEY}"
    echo "Imported public key to AWS as ${KEY_NAME}."
  else
    echo "Key pair exists in AWS."
  fi
fi
echo

# 6) Prepare user-data (backup script)
USER_DATA_FILE=$(mktemp)
cat > "${USER_DATA_FILE}" <<'EOF'
#!/bin/bash
set -e
exec > /var/log/user-data.log 2>&1

# Install awscli, tar, jq
if command -v yum >/dev/null 2>&1; then
  yum update -y
  yum install -y awscli jq tar gzip
elif command -v apt-get >/dev/null 2>&1; then
  apt-get update -y
  apt-get install -y awscli jq tar gzip
fi

BACKUP_DIR="/backup"
mkdir -p "${BACKUP_DIR}"
chown ec2-user:ec2-user "${BACKUP_DIR}" 2>/dev/null || true
chmod 700 "${BACKUP_DIR}"

# Create the application-specific folders under /backup so they get synced to S3
for sub in sales inventory workshop backup; do
  mkdir -p "${BACKUP_DIR}/${sub}"
  # ensure there's at least one file so aws s3 sync uploads the folder
  echo "Seed file for ${sub} created at $(date -u +"%Y-%m-%dT%H:%M:%SZ")" > "${BACKUP_DIR}/${sub}/.seed"
  chown -R ec2-user:ec2-user "${BACKUP_DIR}/${sub}" 2>/dev/null || true
done

BUCKET="__BUCKET__"
HOSTNAME="$(hostname -s)"
INSTANCE_ID="$(curl -s http://169.254.169.254/latest/meta-data/instance-id)"
TIMESTAMP="$(date +%F-%H%M%S)"
ARCHIVE="${BACKUP_DIR}/${HOSTNAME}-fs-backup-${TIMESTAMP}.tar.gz"

# Create filesystem archive (exclude virtual filesystems and backup dir)
tar --exclude=/proc --exclude=/sys --exclude=/dev --exclude=${BACKUP_DIR} --exclude=/tmp --exclude=/run --exclude=/mnt --exclude=/var/tmp -czpf "${ARCHIVE}" /

CREATE_SNAPSHOTS="__CREATE_SNAPSHOTS__"
if [ "${CREATE_SNAPSHOTS}" = "yes" ]; then
  INSTANCE_JSON="$(aws ec2 describe-instances --instance-ids ${INSTANCE_ID})"
  VOL_IDS=$(echo "${INSTANCE_JSON}" | jq -r '.Reservations[].Instances[].BlockDeviceMappings[].Ebs.VolumeId')
  for vol in ${VOL_IDS}; do
    SNAP_DESC="Auto snapshot of ${vol} from ${INSTANCE_ID} at ${TIMESTAMP}"
    SNAP_ID=$(aws ec2 create-snapshot --volume-id "${vol}" --description "${SNAP_DESC}" --query SnapshotId --output text)
    aws ec2 create-tags --resources "${SNAP_ID}" --tags Key=Name,Value="${HOSTNAME}-snapshot" Key=Backup,Value="__SNAP_TAG__"
  done
fi

# Sync to S3 (this will upload /backup and the seeded sales/inventory/workshop folders)
aws s3 sync "${BACKUP_DIR}/" "s3://${BUCKET}/${HOSTNAME}/"

# Keep last 7 archives locally
ls -1t ${BACKUP_DIR}/*fs-backup-*.tar.gz 2>/dev/null | sed -e '1,7d' | xargs -r rm --
EOF

# replace placeholders in user-data
sed -e "s|__BUCKET__|${BUCKET_NAME}|g" \
    -e "s|__CREATE_SNAPSHOTS__|${CREATE_SNAPSHOTS}|g" \
    -e "s|__SNAP_TAG__|${SNAPSHOT_TAG}|g" "${USER_DATA_FILE}" > "${USER_DATA_FILE}.final"

# 7) Launch EC2
echo "6) Launching EC2 instance..."
INSTANCE_JSON=$(aws_run ec2 run-instances \
  --image-id "${AMI_ID}" \
  --instance-type "${INSTANCE_TYPE}" \
  --key-name "${KEY_NAME}" \
  --security-group-ids "${SG_ID}" \
  --iam-instance-profile Name="${INSTANCE_PROFILE_NAME}" \
  --user-data file://"${USER_DATA_FILE}.final" \
  --tag-specifications "ResourceType=instance,Tags=[{Key=Name,Value=${INSTANCE_NAME}}]" \
  --query 'Instances[0]' \
  --output json)

INSTANCE_ID=$(echo "${INSTANCE_JSON}" | jq -r '.InstanceId')
PUBLIC_IP=$(echo "${INSTANCE_JSON}" | jq -r '.PublicIpAddress // "N/A"')
PRIVATE_IP=$(echo "${INSTANCE_JSON}" | jq -r '.PrivateIpAddress')

echo
echo "=== SUCCESS ==="
echo "Instance ID : ${INSTANCE_ID}"
echo "Public IP   : ${PUBLIC_IP}"
echo "Private IP  : ${PRIVATE_IP}"
echo "S3 Bucket   : ${BUCKET_NAME}"
echo "IAM Role    : ${IAM_ROLE_NAME}"
echo
if [ "${PUBLIC_IP}" != "N/A" ]; then
  echo "SSH command: ssh -i ${KEY_NAME}.pem ec2-user@${PUBLIC_IP}"
else
  echo "No public IP assigned. Use Session Manager or a public subnet."
fi

# Cleanup
rm -f "${USER_DATA_FILE}" "${USER_DATA_FILE}.final"

echo
echo "Notes:"
echo "- Restrict SSH ingress (0.0.0.0/0 used here for brevity)."
echo "- For production consider using managed policies and AWS Backup for snapshot lifecycle."
echo "- Created S3 prefixes: ${S3_PREFIXES[*]} and seeded them with README.txt objects."
